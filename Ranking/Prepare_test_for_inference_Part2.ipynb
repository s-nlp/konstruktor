{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cc575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "wdsq = pd.read_csv('wdsq_test_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67ee7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wdsq.loc[25, 'ids_one_hops_dict_en_bela'] = str({'Q605122': 'P131, P31, P1417, P590, P2053, P974, P366, P3858, P1225, P373, P2043, P8189, P625, P403, P910, P885, P18, P15, P646, P17, P1343, P4614, P244'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff63f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [00:07<00:00, 105.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(len(wdsq))):\n",
    "    \n",
    "    inds = np.argsort(ast.literal_eval(wdsq.loc[k, 'bela_base'])[0]['el_scores'])[::-1]\n",
    "\n",
    "    ents_sort =[ast.literal_eval(wdsq.loc[k, 'bela_base'])[0]['entities'][i] for i in inds]\n",
    "    offsets_sort = [ast.literal_eval(wdsq.loc[k, 'bela_base'])[0]['offsets'][i] for i in inds]\n",
    "    lengths_sort = [ast.literal_eval(wdsq.loc[k, 'bela_base'])[0]['lengths'][i] for i in inds]\n",
    "    el_scores = [ast.literal_eval(wdsq.loc[k, 'bela_base'])[0]['el_scores'][i] for i in inds]\n",
    "\n",
    "    cur_set = set()\n",
    "\n",
    "    fin_ents = []\n",
    "    fin_offsets = []\n",
    "    fin_lengths = []\n",
    "    fin_el_scores = []\n",
    "\n",
    "    for j in range(len(ents_sort)):\n",
    "        if ents_sort[j] not in cur_set:\n",
    "            cur_set.add(ents_sort[j])\n",
    "            fin_ents.append(ents_sort[j])\n",
    "            fin_offsets.append(offsets_sort[j])\n",
    "            fin_lengths.append(lengths_sort[j])\n",
    "            fin_el_scores.append(el_scores[j])\n",
    "            \n",
    "    start = fin_offsets[0]\n",
    "    length = fin_lengths[0]\n",
    "    \n",
    "    wdsq.loc[k, 'question_en_rank'] = wdsq.loc[k, 'question'][:start]+'<e>'+wdsq.loc[k, 'question'][start+length:]\n",
    "    wdsq.loc[k, 'scores_en_rank'] = \", \".join(map(str, fin_el_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec24942e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'sparql', 'entity', 'relation', 'answer', 'answer_lbl',\n",
       "       'bela_base', 'bela_base_ents', 'question_en_rank', 'scores_en_rank',\n",
       "       'ids_one_hops_dict_en'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdsq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0616d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "paths = []\n",
    "scores = []\n",
    "origin_questions = []\n",
    "relations = []\n",
    "\n",
    "for k in range(len(wdsq)):\n",
    "    questions.append(wdsq.loc[k, 'question_en_rank'])\n",
    "    cur_dict = ast.literal_eval(wdsq.loc[k, 'ids_one_hops_dict_en'])\n",
    "    for key in cur_dict.keys():\n",
    "        cur_dict[key] = list(cur_dict[key].split(', '))\n",
    "    paths.append(cur_dict)\n",
    "    leng = len(list(wdsq.loc[k, 'scores_en_rank'].split(', ')))\n",
    "    scores.append(list(wdsq.loc[k, 'scores_en_rank'].split(', ')))\n",
    "    origin_questions.append(wdsq.loc[k, 'question'])\n",
    "for q in range(len(wdsq)):\n",
    "    rels_set = set()\n",
    "    for key in paths[q]:\n",
    "        for elem in paths[q][key]:\n",
    "            rels_set.add(elem)\n",
    "    relations.append(list(rels_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb005830",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_re = pd.read_csv('wikidata_properties.csv')\n",
    "all_re = all_re[:11233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c4f158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dict = dict()\n",
    "for i in range(len(all_re)):\n",
    "    cur_id = all_re.loc[i, 'ID']\n",
    "    cur_lbl = all_re.loc[i, 'label']\n",
    "    rel_dict[cur_id] = cur_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595cbc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9fc1b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Q3272', 'Q23397', 'Q4022', 'Q2135'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2600e300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kaley Cuoco'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_rel = list(paths[0].keys())[0]\n",
    "r = requests.get(\"https://www.wikidata.org/w/api.php?action=wbgetentities&props=labels&ids={}&languages=en&formatversion=2&format=json\".format(cur_rel))\n",
    "data = r.json()\n",
    "data['entities'][cur_rel]['labels']['en']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6150170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [01:04<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(range(len(paths))):\n",
    "    for key in paths[p].keys():\n",
    "        for w in range(len(paths[p][key])):\n",
    "            if paths[p][key][w] in rel_dict:\n",
    "                paths[p][key][w] = rel_dict[paths[p][key][w]]\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "                if paths[p][key][w] != '':\n",
    "                    cur_rel = paths[p][key][w]\n",
    "                    r = requests.get(\"https://www.wikidata.org/w/api.php?action=wbgetentities&props=labels&ids={}&languages=en&formatversion=2&format=json\".format(cur_rel))\n",
    "                    data = r.json()\n",
    "                    value = data['entities'][cur_rel]['labels']['en']['value']\n",
    "                    paths[p][key][w] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ecb2206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q3272': ['area',\n",
       "  'Online PWN Encyclopedia ID',\n",
       "  'perimeter',\n",
       "  'NL CR AUT ID',\n",
       "  'described by source',\n",
       "  'vertical depth',\n",
       "  'located in the administrative territorial entity',\n",
       "  'lake outflow',\n",
       "  'has part(s)',\n",
       "  'VIAF ID',\n",
       "  'volume as quantity',\n",
       "  'Great Russian Encyclopedia Online ID (old version)',\n",
       "  'Interlingual Index ID',\n",
       "  'watershed area',\n",
       "  'Freebase ID',\n",
       "  'Getty Thesaurus of Geographic Names ID',\n",
       "  'Encyclopedia of China (Third Edition) ID',\n",
       "  'KBpedia ID',\n",
       "  'locator map image',\n",
       "  'Store norske leksikon ID',\n",
       "  'different from',\n",
       "  'OpenStreetMap relation ID',\n",
       "  'Commons category',\n",
       "  'coordinate location',\n",
       "  'country',\n",
       "  'Gran Enciclopèdia Catalana ID',\n",
       "  'Canadian Encyclopedia article ID',\n",
       "  'GeoNames ID',\n",
       "  'drainage basin',\n",
       "  'inflows',\n",
       "  'on focus list of Wikimedia project',\n",
       "  'CGNDB unique ID',\n",
       "  'category for maps',\n",
       "  'elevation above sea level',\n",
       "  'Encyclopædia Britannica Online ID',\n",
       "  'residence time of water',\n",
       "  'length',\n",
       "  'follows',\n",
       "  'image',\n",
       "  'instance of',\n",
       "  'WordNet 3.1 Synset ID',\n",
       "  \"topic's main category\",\n",
       "  'width'],\n",
       " 'Q23397': ['NL CR AUT ID',\n",
       "  'described by source',\n",
       "  'OmegaWiki Defined Meaning',\n",
       "  'Art & Architecture Thesaurus ID',\n",
       "  'South Carolina Encyclopedia ID',\n",
       "  'Britannica Kids kids level article ID',\n",
       "  'English Vikidia ID',\n",
       "  'subclass of',\n",
       "  'Arabic Ontology ID',\n",
       "  'Gran Enciclopèdia Catalana ID',\n",
       "  'MeSH descriptor ID',\n",
       "  'CALS Encyclopedia of Arkansas ID',\n",
       "  'UMLS CUI',\n",
       "  'Encyclopædia Britannica Online ID',\n",
       "  \"Treccani's Enciclopedia Italiana ID\",\n",
       "  'GND ID',\n",
       "  'OpenStreetMap tag or key',\n",
       "  'GeoNames feature code',\n",
       "  'Freebase ID',\n",
       "  'Encyclopedia of China (Third Edition) ID',\n",
       "  \"topic's main template\",\n",
       "  'Mississippi Encyclopedia ID',\n",
       "  'YSO ID',\n",
       "  'KBpedia ID',\n",
       "  'EuroVoc ID',\n",
       "  'Commons category',\n",
       "  'Bibliothèque nationale de France ID',\n",
       "  'UNESCO Thesaurus ID',\n",
       "  'Krugosvet article',\n",
       "  'category for the view of the item',\n",
       "  'PSH ID',\n",
       "  'French Vikidia ID',\n",
       "  'Encyclopedia of Korean Culture ID',\n",
       "  \"topic's main category\",\n",
       "  'JSTOR topic ID',\n",
       "  'Spanish Vikidia ID',\n",
       "  'STW Thesaurus for Economics ID',\n",
       "  'Treccani ID',\n",
       "  'ASC Leiden Thesaurus ID',\n",
       "  'BBC Things ID',\n",
       "  'Store norske leksikon ID',\n",
       "  'different from',\n",
       "  'MeSH tree code',\n",
       "  'Library of Congress authority ID',\n",
       "  'on focus list of Wikimedia project',\n",
       "  'PACTOLS thesaurus ID',\n",
       "  'image',\n",
       "  'Zhihu topic ID',\n",
       "  'FactGrid item ID',\n",
       "  'Britannica Kids students level article ID',\n",
       "  'maintained by WikiProject',\n",
       "  'Online PWN Encyclopedia ID',\n",
       "  'exact match',\n",
       "  'Environment Ontology ID',\n",
       "  'Commons gallery',\n",
       "  'Wolfram Language entity type',\n",
       "  'National Library of Israel J9U ID',\n",
       "  'Klexikon article ID',\n",
       "  'UK Parliament thesaurus ID',\n",
       "  'Britannica Kids scholars level article ID',\n",
       "  'FOIH heritage types ID',\n",
       "  'Quora topic ID',\n",
       "  'Great Russian Encyclopedia Online ID (old version)',\n",
       "  'Encyclopædia Universalis ID',\n",
       "  'studied by',\n",
       "  'category for eponymous categories',\n",
       "  'properties for this type',\n",
       "  'BabelNet ID',\n",
       "  'BNCF Thesaurus ID',\n",
       "  'Den Store Danske ID',\n",
       "  'e-WV: The West Virginia Encyclopedia ID',\n",
       "  'YSA ID',\n",
       "  'U.S. National Archives Identifier',\n",
       "  'equivalent class',\n",
       "  'Maine: An Encyclopedia ID',\n",
       "  'RKD thesaurus ID',\n",
       "  'Australian Educational Vocabulary ID',\n",
       "  'NALT ID',\n",
       "  'NLS place type ID',\n",
       "  'Yle topic ID',\n",
       "  'WordNet 3.1 Synset ID'],\n",
       " 'Q4022': ['BBC News topic ID',\n",
       "  'model item',\n",
       "  'NL CR AUT ID',\n",
       "  'described by source',\n",
       "  'OmegaWiki Defined Meaning',\n",
       "  'MeSH term ID',\n",
       "  'Art & Architecture Thesaurus ID',\n",
       "  'IPTC NewsCode',\n",
       "  'has part(s)',\n",
       "  'Britannica Kids kids level article ID',\n",
       "  'Analysis & Policy Observatory term ID',\n",
       "  'English Vikidia ID',\n",
       "  'Iconclass notation',\n",
       "  'De Agostini ID',\n",
       "  'Golden ID',\n",
       "  'Thesaurus for Graphic Materials ID',\n",
       "  'subclass of',\n",
       "  'Biblioteca Nacional de España ID',\n",
       "  'Arabic Ontology ID',\n",
       "  'Gran Enciclopèdia Catalana ID',\n",
       "  'MeSH descriptor ID',\n",
       "  'Giant Bomb ID',\n",
       "  'UMLS CUI',\n",
       "  'Encyclopædia Britannica Online ID',\n",
       "  \"Treccani's Enciclopedia Italiana ID\",\n",
       "  'part of',\n",
       "  'GND ID',\n",
       "  'OpenStreetMap tag or key',\n",
       "  'GeoNames feature code',\n",
       "  'Freebase ID',\n",
       "  \"topic's main template\",\n",
       "  'YSO ID',\n",
       "  'KBpedia ID',\n",
       "  'Banglapedia ID (Bengali)',\n",
       "  'EuroVoc ID',\n",
       "  'Commons category',\n",
       "  'UNESCO Thesaurus ID',\n",
       "  'Krugosvet article',\n",
       "  'category for the view of the item',\n",
       "  'French Vikidia ID',\n",
       "  'Great Russian Encyclopedia portal ID',\n",
       "  'said to be the same as',\n",
       "  \"topic's main category\",\n",
       "  'Joconde discovery ID',\n",
       "  'JSTOR topic ID',\n",
       "  'Pleiades category ID',\n",
       "  'Spanish Vikidia ID',\n",
       "  'ABC News topic ID',\n",
       "  'STW Thesaurus for Economics ID',\n",
       "  'FAST ID',\n",
       "  'video',\n",
       "  'Treccani ID',\n",
       "  'ASC Leiden Thesaurus ID',\n",
       "  'BBC Things ID',\n",
       "  'Punjabipedia ID',\n",
       "  'Store norske leksikon ID',\n",
       "  'different from',\n",
       "  'MeSH tree code',\n",
       "  'Basque Vikidia ID',\n",
       "  'Library of Congress authority ID',\n",
       "  'on focus list of Wikimedia project',\n",
       "  'PACTOLS thesaurus ID',\n",
       "  'Digital Atlas of Idaho URL',\n",
       "  'image',\n",
       "  'Zhihu topic ID',\n",
       "  'FactGrid item ID',\n",
       "  'Britannica Kids students level article ID',\n",
       "  'MeSH concept ID',\n",
       "  'has list',\n",
       "  'exact match',\n",
       "  'Environment Ontology ID',\n",
       "  'Commons gallery',\n",
       "  'Wolfram Language entity type',\n",
       "  'National Library of Israel J9U ID',\n",
       "  'Klexikon article ID',\n",
       "  'UK Parliament thesaurus ID',\n",
       "  'Britannica Kids scholars level article ID',\n",
       "  'Quora topic ID',\n",
       "  'Great Russian Encyclopedia Online ID (old version)',\n",
       "  'permanent duplicated item',\n",
       "  'category for eponymous categories',\n",
       "  'properties for this type',\n",
       "  'BNCF Thesaurus ID',\n",
       "  'Den Store Danske ID',\n",
       "  'YSA ID',\n",
       "  'U.S. National Archives Identifier',\n",
       "  'equivalent class',\n",
       "  'Italian Vikidia ID',\n",
       "  'RKD thesaurus ID',\n",
       "  'Australian Educational Vocabulary ID',\n",
       "  'NALT ID',\n",
       "  'Yle topic ID',\n",
       "  'WordNet 3.1 Synset ID',\n",
       "  'pronunciation audio'],\n",
       " 'Q2135': ['area',\n",
       "  'BBC News topic ID',\n",
       "  'NL CR AUT ID',\n",
       "  'described by source',\n",
       "  'YouTube channel ID',\n",
       "  'shares border with',\n",
       "  \"Who's on First ID\",\n",
       "  'social media followers',\n",
       "  'page banner',\n",
       "  'coat of arms image',\n",
       "  'named after',\n",
       "  'Getty Thesaurus of Geographic Names ID',\n",
       "  'head of government',\n",
       "  'flag',\n",
       "  'coordinate location',\n",
       "  'country',\n",
       "  'Gran Enciclopèdia Catalana ID',\n",
       "  'Google Arts & Culture entity ID',\n",
       "  'Dewey Decimal Classification',\n",
       "  'office held by head of government',\n",
       "  'Encyclopædia Britannica Online ID',\n",
       "  \"Treccani's Dizionario di Storia ID\",\n",
       "  'flag image',\n",
       "  'official website',\n",
       "  'owner of',\n",
       "  'WorldCat Identities ID (superseded)',\n",
       "  'part of',\n",
       "  'Curlie ID',\n",
       "  'GND ID',\n",
       "  'VIAF ID',\n",
       "  'Freebase ID',\n",
       "  'related category',\n",
       "  'locator map image',\n",
       "  'Encyclopedia of Modern Ukraine ID',\n",
       "  'OpenStreetMap relation ID',\n",
       "  'OSM Name Suggestion Index ID',\n",
       "  'Commons category',\n",
       "  'Bibliothèque nationale de France ID',\n",
       "  'category for people who died here',\n",
       "  'elevation above sea level',\n",
       "  'archives at',\n",
       "  'category for people born here',\n",
       "  'Wikisimpsons ID',\n",
       "  'instance of',\n",
       "  \"topic's main category\",\n",
       "  'subreddit',\n",
       "  'capital of',\n",
       "  'FAST ID',\n",
       "  'continent',\n",
       "  'escutcheon image',\n",
       "  'museum-digital place ID',\n",
       "  'motto text',\n",
       "  'Comic Vine ID',\n",
       "  'Statistics Canada Geographic code',\n",
       "  'BBC Things ID',\n",
       "  'population',\n",
       "  'local dialing code',\n",
       "  'Store norske leksikon ID',\n",
       "  'different from',\n",
       "  'category of associated people',\n",
       "  'archINFORM location ID',\n",
       "  'Library of Congress authority ID',\n",
       "  'category for maps',\n",
       "  'category for films shot at this location',\n",
       "  'open data portal',\n",
       "  'image',\n",
       "  'FactGrid item ID',\n",
       "  'legislative body',\n",
       "  'Jewish Encyclopedia ID',\n",
       "  'located in or next to body of water',\n",
       "  'Reddit topic ID',\n",
       "  'Online PWN Encyclopedia ID',\n",
       "  \"topic's main Wikimedia portal\",\n",
       "  'Commons gallery',\n",
       "  'National Library of Israel J9U ID',\n",
       "  'postal code',\n",
       "  'located in the administrative territorial entity',\n",
       "  'official name',\n",
       "  'iNaturalist place ID',\n",
       "  'Internet Encyclopedia of Ukraine ID',\n",
       "  'licence plate code',\n",
       "  'Quora topic ID',\n",
       "  'Great Russian Encyclopedia Online ID (old version)',\n",
       "  'Interlingual Index ID',\n",
       "  'Den Store Danske ID',\n",
       "  'twinned administrative body',\n",
       "  'inception',\n",
       "  'U.S. National Archives Identifier',\n",
       "  'category of people buried here',\n",
       "  'RKD thesaurus ID',\n",
       "  'located in time zone',\n",
       "  'Facebook Places ID',\n",
       "  'GeoNames ID',\n",
       "  'collage image',\n",
       "  'coat of arms',\n",
       "  'CGNDB unique ID',\n",
       "  'economy of topic',\n",
       "  'demographics of topic',\n",
       "  'MusicBrainz area ID',\n",
       "  'WordNet 3.1 Synset ID',\n",
       "  'demonym',\n",
       "  'pronunciation audio']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7806ef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [01:00<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(range(len(relations))):\n",
    "    for q in range(len(relations[p])):\n",
    "        if relations[p][q] in rel_dict:\n",
    "            relations[p][q] = rel_dict[relations[p][q]]\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "            if relations[p][q] != '':\n",
    "                cur_rel = relations[p][q]\n",
    "                r = requests.get(\"https://www.wikidata.org/w/api.php?action=wbgetentities&props=labels&ids={}&languages=en&formatversion=2&format=json\".format(cur_rel))\n",
    "                data = r.json()\n",
    "                value = data['entities'][cur_rel]['labels']['en']['value']\n",
    "                relations[p][q] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4703561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ef10a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test_json=dict()\n",
    "test_json[\"questions\"]=questions\n",
    "test_json[\"paths\"]=paths\n",
    "test_json[\"scores\"]=scores\n",
    "test_json[\"origin_questions\"]=origin_questions\n",
    "test_json[\"relations\"]=relations\n",
    "\n",
    "with open('test_mintaka_dates.json', 'w') as f:\n",
    "    json.dump(test_json, f,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f85581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('test_mintaka_dates.json') as user_file:\n",
    "    parsed_json = json.load(user_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30fcf8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "paths = parsed_json['paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f7273e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:00<00:00, 13558.40it/s]\n"
     ]
    }
   ],
   "source": [
    "del_list = []\n",
    "for p in tqdm(range(len(parsed_json['paths']))):\n",
    "    for key in parsed_json['paths'][p].keys():\n",
    "        for w in range(len(parsed_json['paths'][p][key])):\n",
    "            if parsed_json['paths'][p][key][w] == '':\n",
    "                del_list.append([p, key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4dbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(del_list)):\n",
    "    id1 = del_list[i][0]\n",
    "    id2 = del_list[i][1]\n",
    "    del parsed_json['paths'][id1][id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9973a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_wdsq.json', 'w') as f:\n",
    "    json.dump(parsed_json, f,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6829ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|███████| 28.0/28.0 [00:00<00:00, 401B/s]\n",
      "Downloading config.json: 100%|██████████████████| 483/483 [00:00<00:00, 283kB/s]\n",
      "Downloading vocab.txt: 100%|█████████████████| 226k/226k [00:00<00:00, 3.04MB/s]\n",
      "Downloading tokenizer.json: 100%|████████████| 455k/455k [00:00<00:00, 5.08MB/s]\n",
      "loaded tokenizer!\n",
      "Downloading pytorch_model.bin: 100%|█████████| 256M/256M [00:05<00:00, 49.8MB/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Bert_Comparing(\n",
      "  (question_bert_embedding): BertCharEmbedding(\n",
      "    (bert): DistilBertModel(\n",
      "      (embeddings): Embeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (layer): ModuleList(\n",
      "          (0): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (1): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (2): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (3): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (4): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (5): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (path_bert_embedding): BertCharEmbedding(\n",
      "    (bert): DistilBertModel(\n",
      "      (embeddings): Embeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (layer): ModuleList(\n",
      "          (0): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (1): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (2): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (3): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (4): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (5): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (similarity): CosineSimilarity()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model!\n",
      "��Ԥ�⣺ 500 / 824\n",
      "Ԥ����ȣ� 0.6067961165048543\n"
     ]
    }
   ],
   "source": [
    "! python3 PLMs-in-Practical-KBQA/main/rel_similarity/predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c24d448",
   "metadata": {},
   "source": [
    "### Mintaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a328ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mintaka = pd.read_csv('mintaka_paper_res_sel_rank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb8450f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "paths = []\n",
    "scores = []\n",
    "origin_questions = []\n",
    "relations = []\n",
    "\n",
    "for k in range(len(mintaka)):\n",
    "    questions.append(mintaka.loc[k, 'question_en_rank'])\n",
    "    cur_dict = ast.literal_eval(mintaka.loc[k, 'ids_one_hops_dict_en'])\n",
    "    for key in cur_dict.keys():\n",
    "        cur_dict[key] = list(cur_dict[key].split(', '))\n",
    "    paths.append(cur_dict)\n",
    "    scores.append(list(mintaka.loc[k, 'scores_en_rank'].split(', ')))\n",
    "    origin_questions.append(mintaka.loc[k, 'question'])\n",
    "for q in range(len(mintaka)):\n",
    "    rels_set = set()\n",
    "    for key in paths[q]:\n",
    "        for elem in paths[q][key]:\n",
    "            rels_set.add(elem)\n",
    "    relations.append(list(rels_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7009fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [00:45<00:00,  7.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "for p in tqdm(range(len(paths))):\n",
    "    for key in paths[p].keys():\n",
    "        for w in range(len(paths[p][key])):\n",
    "            if paths[p][key][w] in rel_dict:\n",
    "                paths[p][key][w] = rel_dict[paths[p][key][w]]\n",
    "            else:\n",
    "                time.sleep(1)\n",
    "                if paths[p][key][w] != '':\n",
    "                    cur_rel = paths[p][key][w]\n",
    "                    r = requests.get(\"https://www.wikidata.org/w/api.php?action=wbgetentities&props=labels&ids={}&languages=en&formatversion=2&format=json\".format(cur_rel))\n",
    "                    data = r.json()\n",
    "                    value = data['entities'][cur_rel]['labels']['en']['value']\n",
    "                    paths[p][key][w] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2539fbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [00:00<00:00, 10298.76it/s]\n"
     ]
    }
   ],
   "source": [
    "del_list = []\n",
    "for p in tqdm(range(len(parsed_json['paths']))):\n",
    "    for key in parsed_json['paths'][p].keys():\n",
    "        for w in range(len(parsed_json['paths'][p][key])):\n",
    "            if parsed_json['paths'][p][key][w] == '':\n",
    "                del_list.append([p, key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7f2a415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [00:45<00:00,  7.47it/s]\n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(range(len(relations))):\n",
    "    for q in range(len(relations[p])):\n",
    "        if relations[p][q] in rel_dict:\n",
    "            relations[p][q] = rel_dict[relations[p][q]]\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "            if relations[p][q] != '':\n",
    "                cur_rel = relations[p][q]\n",
    "                r = requests.get(\"https://www.wikidata.org/w/api.php?action=wbgetentities&props=labels&ids={}&languages=en&formatversion=2&format=json\".format(cur_rel))\n",
    "                data = r.json()\n",
    "                value = data['entities'][cur_rel]['labels']['en']['value']\n",
    "                relations[p][q] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d3a9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test_json=dict()\n",
    "test_json[\"questions\"]=questions\n",
    "test_json[\"paths\"]=paths\n",
    "test_json[\"scores\"]=scores\n",
    "test_json[\"origin_questions\"]=origin_questions\n",
    "test_json[\"relations\"]=relations\n",
    "\n",
    "with open('test_mintaka.json', 'w') as f:\n",
    "    json.dump(test_json, f,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac9dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded tokenizer!\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Bert_Comparing(\n",
      "  (question_bert_embedding): BertCharEmbedding(\n",
      "    (bert): DistilBertModel(\n",
      "      (embeddings): Embeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (layer): ModuleList(\n",
      "          (0): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (1): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (2): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (3): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (4): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (5): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (path_bert_embedding): BertCharEmbedding(\n",
      "    (bert): DistilBertModel(\n",
      "      (embeddings): Embeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (layer): ModuleList(\n",
      "          (0): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (1): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (2): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (3): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (4): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (5): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (activation): GELUActivation()\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (similarity): CosineSimilarity()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model!\r\n"
     ]
    }
   ],
   "source": [
    "! python3 PLMs-in-Practical-KBQA/main/rel_similarity/predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "564f68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubq = pd.read_csv('rubq_paper_res_sel_rank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bebc3aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubq.to_csv('rubq_paper_res_sel_rank.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9eaf3135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rubq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04ba344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/distilbert-base-uncased/rubq_en/result.json') as user_file:\n",
    "    res = json.load(user_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53b4496d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['re_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "226ae5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [00:00<00:00, 4468.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(res['re_scores']))):\n",
    "    subj, rel = best_label(res, i)\n",
    "    rubq.loc[i, 'subj_rank'] = subj\n",
    "    rubq.loc[i, 'rel_rank'] = rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c113f750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [00:00<00:00, 11516.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(rubq))):\n",
    "    lbl = rubq.loc[i, 'rel_rank']\n",
    "    rubq.loc[i, 'rel_rank_id'] = rel_dict_rev[lbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "50482f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(rubq)):\n",
    "    true_id = rubq.loc[i, 'props_labs']\n",
    "    pred_id = rubq.loc[i, 'rel_rank_id']\n",
    "    if true_id == pred_id:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9db8d72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5657672849915683"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/len(rubq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6030006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5733558178752108"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/len(rubq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e581de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubq.to_csv('rubq_paper_res_sel_rank.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e91dc9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'question', 'subject', 'props', 'query', 'tag', 'answers',\n",
       "       'pred_relation', 'pred_obj', 'pred_on_wdsq_and_rubq_for_rubq_ner_upd',\n",
       "       'ans_type', 'ans_correct', 'object_gold', 'pred_prop_fast',\n",
       "       'pred_joined', 'max_pred_label', 'props_labs', 'max_pred_id',\n",
       "       'pred_init', 'pred_fast', 'pred_t5', 'pred_combo', 'pred_joined_sel',\n",
       "       'pred_ids', 'appr', 'bela_base_ents', 'pred_bela_ner_ru',\n",
       "       'mgenre_with_bela_en_ques', 'mgenre_with_bela_ru_ques', 'bela_base',\n",
       "       'question_text', 'bela_base_ru', 'scores_bela_ner_ru',\n",
       "       'pred_prop_fast_en', 'pred_prop_fast_ru', 'pred_obj_fall_init_ru',\n",
       "       'pred_obj_fall_init_en', 'pred_fin_en', 'pred_fin_ru', 'ents_falcon',\n",
       "       'rels_falcon', 'question_en_rank', 'scores_en_rank',\n",
       "       'ids_one_hops_dict_en', 'subj_rank', 'rel_rank', 'rel_rank_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b14a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query_object(entity_idx, property_idx):\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "    query = \"\"\"\n",
    "\n",
    "   SELECT ?object  WHERE {\n",
    "\n",
    "   wd:<ENTITY> wdt:<PROPERTY> ?object .} \n",
    "        \"\"\".replace(\n",
    "            \"<ENTITY>\", entity_idx).replace(\n",
    "            \"<PROPERTY>\", property_idx)\n",
    "     \n",
    "    request = requests.get(url, params={\"format\": \"json\", \"query\": query})\n",
    "    data = request.json()\n",
    "    objects = []\n",
    "    for q in range(len(data[\"results\"]['bindings'])):\n",
    "        objects.append(data[\"results\"]['bindings'][q]['object']['value'])                 \n",
    "    return ', '.join(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9ec30157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [25:35<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(rubq))):\n",
    "    subj = rubq.loc[i, 'subj_rank']\n",
    "    rel = rubq.loc[i, 'rel_rank_id']\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        ans = run_query_object(subj, rel)\n",
    "        rubq.loc[i, 'ans_rank'] = ans\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4985420b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [00:00<00:00, 9601.01it/s]\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm(range(len(rubq))):\n",
    "    cands = rubq.loc[j, 'ans_rank'].split(', ')\n",
    "    elems = []\n",
    "    for k in range(len(cands)):\n",
    "        if 'entity/' in cands[k]:\n",
    "            elems.append(cands[k].split('entity/')[1])\n",
    "        else:\n",
    "            elems.append(cands[k])\n",
    "    rubq.loc[j, 'ans_rank_clean'] = ', '.join(elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4b54a8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4527824620573356\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(rubq)):\n",
    "    if rubq.loc[i, 'answers'] == rubq.loc[i, 'ans_rank_clean']:\n",
    "        count += 1\n",
    "print(count/len(rubq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4ee81ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4620573355817875\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(rubq)):\n",
    "    if rubq.loc[i, 'answers'] == rubq.loc[i, 'pred_obj_maxpred_lbl']:\n",
    "        count += 1\n",
    "print(count/len(rubq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95fb6768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'uid', 'question', 'subject', 'props', 'query', 'tag',\n",
       "       'answers', 'pred_relation', 'pred_obj',\n",
       "       'pred_on_wdsq_and_rubq_for_rubq_ner_upd', 'ans_type', 'ans_correct',\n",
       "       'object_gold', 'pred_prop_fast', 'pred_joined', 'max_pred_label',\n",
       "       'props_labs', 'max_pred_id', 'pred_init', 'pred_fast', 'pred_t5',\n",
       "       'pred_combo', 'pred_joined_sel', 'pred_ids', 'appr', 'bela_base_ents',\n",
       "       'pred_bela_ner_ru', 'mgenre_with_bela_en_ques',\n",
       "       'mgenre_with_bela_ru_ques', 'bela_base', 'question_text',\n",
       "       'bela_base_ru', 'scores_bela_ner_ru', 'pred_prop_fast_en',\n",
       "       'pred_prop_fast_ru', 'pred_obj_fall_init_ru', 'pred_obj_fall_init_en',\n",
       "       'pred_fin_en', 'pred_fin_ru', 'ents_falcon', 'rels_falcon',\n",
       "       'question_en_rank', 'scores_en_rank', 'ids_one_hops_dict_en',\n",
       "       'subj_rank', 'rel_rank', 'rel_rank_id', 'ans_rank', 'ans_rank_clean',\n",
       "       'pred_obj_maxpred', 'ans_class_rank', 'pred_obj_maxpred_lbl',\n",
       "       'pred_rel_rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "038ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rubq)):\n",
    "    if pd.notna(rubq.loc[i, 'pred_obj_maxpred_lbl']):\n",
    "        rubq.loc[i, 'pred_rel_rank'] = rubq.loc[i, 'pred_obj_maxpred_lbl']\n",
    "    else:\n",
    "        rubq.loc[i, 'pred_rel_rank'] = rubq.loc[i, 'ans_rank_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3d08bedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5101180438448567\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(rubq)):\n",
    "    if rubq.loc[i, 'answers'] == rubq.loc[i, 'pred_rel_rank']:\n",
    "        count += 1\n",
    "print(count/len(rubq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05b6010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(rubq)):\n",
    "    if rubq.loc[i, 'answers'] == rubq.loc[i, 'pred_obj_fall_init_en']:\n",
    "        count += 1\n",
    "print(count/len(rubq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff29699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "df4195a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'question', 'subject', 'props', 'query', 'tag', 'answers',\n",
       "       'pred_relation', 'pred_obj', 'pred_on_wdsq_and_rubq_for_rubq_ner_upd',\n",
       "       'ans_type', 'ans_correct', 'object_gold', 'pred_prop_fast',\n",
       "       'pred_joined', 'max_pred_label', 'props_labs', 'max_pred_id',\n",
       "       'pred_init', 'pred_fast', 'pred_t5', 'pred_combo', 'pred_joined_sel',\n",
       "       'pred_ids', 'appr', 'bela_base_ents', 'pred_bela_ner_ru',\n",
       "       'mgenre_with_bela_en_ques', 'mgenre_with_bela_ru_ques', 'bela_base',\n",
       "       'question_text', 'bela_base_ru', 'scores_bela_ner_ru',\n",
       "       'pred_prop_fast_en', 'pred_prop_fast_ru', 'pred_obj_fall_init_ru',\n",
       "       'pred_obj_fall_init_en', 'pred_fin_en', 'pred_fin_ru', 'ents_falcon',\n",
       "       'rels_falcon', 'question_en_rank', 'scores_en_rank',\n",
       "       'ids_one_hops_dict_en', 'subj_rank', 'rel_rank', 'rel_rank_id',\n",
       "       'ans_rank', 'ans_rank_clean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f0861d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'Q176772': 'P8419, P509, P463, P1559, P20, P1449, P22, P175, P569, P735, P170, P551, P460, P607, P157, P2563, P6262, P27, P7047, P734, P3417, P19, P1412, P25, P10757, P21, P8345, P1080, P7818, P11408, P18, P39, P1196, P570, P2561, P646, P69, P4584, P11196, P108, P941, P373, P3342, P31, P106, P1441, P5905', 'Q82799': 'P8834, P1687, P6573, P11567, P7827, P1282, P1709, P5008, P460, P5395, P9318, P1889, P2559, P279, P1225, P3417, P3827, P8189, P1557, P227, P2572, P7818, P8885, P18, P361, P2888, P527, P1296, P8168, P5198, P646, P1368, P1036, P3123, P4212, P910, P3219, P244, P1417, P9475, P373, P8313, P1014, P691, P1343, P2581, P8408, P4613, P8814', 'Q7565': 'P4946, P902, P950, P8309, P486, P1687, P7033, P9497, P268, P2892, P6417, P8015, P4527, P9937, P9318, P10913, P1889, P3827, P279, P3417, P8189, P5160, P227, P508, P443, P461, P18, P527, P1245, P2004, P1296, P8168, P6366, P8370, P8519, P5198, P646, P1552, P4500, P1036, P3984, P6293, P4212, P7870, P910, P244, P3916, P1417, P672, P10192, P9475, P373, P31, P4316, P2347, P1014, P691, P1343, P1617, P2581, P8408, P8814'}\""
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubq.loc[14, 'ids_one_hops_dict_en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0a751b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_pred_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>P1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>P50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>P170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>P138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>P1880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1186 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_pred_id\n",
       "0           P828\n",
       "1            P50\n",
       "2            P50\n",
       "3            P36\n",
       "4          P1303\n",
       "...          ...\n",
       "1181       P1299\n",
       "1182         P50\n",
       "1183        P170\n",
       "1184        P138\n",
       "1185       P1880\n",
       "\n",
       "[1186 rows x 1 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubq[['max_pred_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d753104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query_subject(entity_idx, property_idx):\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "    query = \"\"\"\n",
    "\n",
    "   SELECT ?object  WHERE {\n",
    "\n",
    "   ?object wdt:<PROPERTY> wd:<ENTITY> .} \n",
    "        \"\"\".replace(\n",
    "            \"<ENTITY>\", entity_idx).replace(\n",
    "            \"<PROPERTY>\", property_idx)\n",
    "     \n",
    "    request = requests.get(url, params={\"format\": \"json\", \"query\": query})\n",
    "    data = request.json()\n",
    "    objects = []\n",
    "    for q in range(len(data[\"results\"]['bindings'])):\n",
    "        objects.append(data[\"results\"]['bindings'][q]['object']['value'])                 \n",
    "    return ', '.join(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ebf9a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>question</th>\n",
       "      <th>subject</th>\n",
       "      <th>props</th>\n",
       "      <th>query</th>\n",
       "      <th>tag</th>\n",
       "      <th>answers</th>\n",
       "      <th>pred_relation</th>\n",
       "      <th>pred_obj</th>\n",
       "      <th>...</th>\n",
       "      <th>scores_en_rank</th>\n",
       "      <th>ids_one_hops_dict_en</th>\n",
       "      <th>subj_rank</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>rel_rank_id</th>\n",
       "      <th>ans_rank</th>\n",
       "      <th>ans_rank_clean</th>\n",
       "      <th>pred_obj_maxpred</th>\n",
       "      <th>ans_class_rank</th>\n",
       "      <th>pred_obj_maxpred_lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>What can cause a tsunami?</td>\n",
       "      <td>Q8070</td>\n",
       "      <td>wdt:P828</td>\n",
       "      <td>SELECT ?answer \\nWHERE {\\n  wd:Q8070 wdt:P828 ...</td>\n",
       "      <td>1-hop</td>\n",
       "      <td>Q7944, Q60186, Q167903, Q2580904, Q5975740, Q7...</td>\n",
       "      <td>P2528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8407442569732666</td>\n",
       "      <td>{'Q8070': 'P487, P948, P3221, P950, P486, P703...</td>\n",
       "      <td>Q8070</td>\n",
       "      <td>has cause</td>\n",
       "      <td>P828</td>\n",
       "      <td>http://www.wikidata.org/entity/Q7944, http://w...</td>\n",
       "      <td>Q7944, Q60186, Q167903, Q2580904, Q5975740, Q7...</td>\n",
       "      <td>http://www.wikidata.org/entity/Q7944, http://w...</td>\n",
       "      <td>Q7944, Q60186, Q167903, Q2580904, Q5975740, Q7...</td>\n",
       "      <td>Q7944, Q60186, Q167903, Q2580904, Q5975740, Q7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Who wrote the novel \"uncle Tom's Cabin\"?</td>\n",
       "      <td>Q2222</td>\n",
       "      <td>wdt:P50</td>\n",
       "      <td>SELECT ?answer \\nWHERE {\\n  wd:Q2222 wdt:P50 ?...</td>\n",
       "      <td>1-hop</td>\n",
       "      <td>Q102513</td>\n",
       "      <td>P50</td>\n",
       "      <td>Q102513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38015487790107727, 0.06446564197540283, 0.01...</td>\n",
       "      <td>{'Q2222': 'P50, P747, P110, P950, P409, P136, ...</td>\n",
       "      <td>Q2222</td>\n",
       "      <td>author</td>\n",
       "      <td>P50</td>\n",
       "      <td>http://www.wikidata.org/entity/Q102513</td>\n",
       "      <td>Q102513</td>\n",
       "      <td>http://www.wikidata.org/entity/Q102513</td>\n",
       "      <td>Q102513</td>\n",
       "      <td>Q102513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Who is the author of the play \"Romeo and Juliet\"?</td>\n",
       "      <td>Q83186</td>\n",
       "      <td>wdt:P50</td>\n",
       "      <td>SELECT ?answer \\nWHERE {\\n  wd:Q83186 wdt:P50 ...</td>\n",
       "      <td>1-hop</td>\n",
       "      <td>Q692</td>\n",
       "      <td>P50</td>\n",
       "      <td>Q692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9108105301856995, 0.020021561533212662, 0.00...</td>\n",
       "      <td>{'Q83186': 'P2348, P50, P7439, P747, P8419, P8...</td>\n",
       "      <td>Q83186</td>\n",
       "      <td>author</td>\n",
       "      <td>P50</td>\n",
       "      <td>http://www.wikidata.org/entity/Q692</td>\n",
       "      <td>Q692</td>\n",
       "      <td>http://www.wikidata.org/entity/Q692</td>\n",
       "      <td>Q692</td>\n",
       "      <td>Q692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the name of the capital of Romania?</td>\n",
       "      <td>Q218</td>\n",
       "      <td>wdt:P36</td>\n",
       "      <td>SELECT ?answer \\nWHERE {\\n  wd:Q218 wdt:P36 ?a...</td>\n",
       "      <td>1-hop</td>\n",
       "      <td>Q19660</td>\n",
       "      <td>P1376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8396620154380798, 0.12966066598892212, 0.043...</td>\n",
       "      <td>{'Q218': 'P38, P902, P487, P948, P463, P8309, ...</td>\n",
       "      <td>Q218</td>\n",
       "      <td>capital</td>\n",
       "      <td>P36</td>\n",
       "      <td>http://www.wikidata.org/entity/Q19660</td>\n",
       "      <td>Q19660</td>\n",
       "      <td>http://www.wikidata.org/entity/Q19660</td>\n",
       "      <td>Q19660</td>\n",
       "      <td>Q19660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>What instrument did Jimi Hendrix play?</td>\n",
       "      <td>Q5928</td>\n",
       "      <td>wdt:P1303</td>\n",
       "      <td>SELECT ?answer \\nWHERE {\\n  wd:Q5928 wdt:P1303...</td>\n",
       "      <td>1-hop</td>\n",
       "      <td>Q6607, Q483994, Q626035, Q2643890, Q17172850</td>\n",
       "      <td>P1303</td>\n",
       "      <td>Q6607, Q483994, Q626035, Q2643890, Q17172850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9030609130859375, 0.057044822722673416</td>\n",
       "      <td>{'Q5928': 'P11194, P463, P8041, P2722, P22, P4...</td>\n",
       "      <td>Q5928</td>\n",
       "      <td>instrument</td>\n",
       "      <td>P1303</td>\n",
       "      <td>http://www.wikidata.org/entity/Q6607, http://w...</td>\n",
       "      <td>Q6607, Q483994, Q626035, Q17172850</td>\n",
       "      <td>http://www.wikidata.org/entity/Q6607, http://w...</td>\n",
       "      <td>Q6607, Q483994, Q626035, Q17172850</td>\n",
       "      <td>Q6607, Q483994, Q626035, Q17172850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  uid                                           question subject  \\\n",
       "0           0    0                          What can cause a tsunami?   Q8070   \n",
       "1           1    1           Who wrote the novel \"uncle Tom's Cabin\"?   Q2222   \n",
       "2           2    2  Who is the author of the play \"Romeo and Juliet\"?  Q83186   \n",
       "3           3    3        What is the name of the capital of Romania?    Q218   \n",
       "4           4    5             What instrument did Jimi Hendrix play?   Q5928   \n",
       "\n",
       "       props                                              query    tag  \\\n",
       "0   wdt:P828  SELECT ?answer \\nWHERE {\\n  wd:Q8070 wdt:P828 ...  1-hop   \n",
       "1    wdt:P50  SELECT ?answer \\nWHERE {\\n  wd:Q2222 wdt:P50 ?...  1-hop   \n",
       "2    wdt:P50  SELECT ?answer \\nWHERE {\\n  wd:Q83186 wdt:P50 ...  1-hop   \n",
       "3    wdt:P36  SELECT ?answer \\nWHERE {\\n  wd:Q218 wdt:P36 ?a...  1-hop   \n",
       "4  wdt:P1303  SELECT ?answer \\nWHERE {\\n  wd:Q5928 wdt:P1303...  1-hop   \n",
       "\n",
       "                                             answers pred_relation  \\\n",
       "0  Q7944, Q60186, Q167903, Q2580904, Q5975740, Q7...         P2528   \n",
       "1                                            Q102513           P50   \n",
       "2                                               Q692           P50   \n",
       "3                                             Q19660         P1376   \n",
       "4       Q6607, Q483994, Q626035, Q2643890, Q17172850         P1303   \n",
       "\n",
       "                                       pred_obj  ...  \\\n",
       "0                                           NaN  ...   \n",
       "1                                       Q102513  ...   \n",
       "2                                          Q692  ...   \n",
       "3                                           NaN  ...   \n",
       "4  Q6607, Q483994, Q626035, Q2643890, Q17172850  ...   \n",
       "\n",
       "                                      scores_en_rank  \\\n",
       "0                                 0.8407442569732666   \n",
       "1  0.38015487790107727, 0.06446564197540283, 0.01...   \n",
       "2  0.9108105301856995, 0.020021561533212662, 0.00...   \n",
       "3  0.8396620154380798, 0.12966066598892212, 0.043...   \n",
       "4           0.9030609130859375, 0.057044822722673416   \n",
       "\n",
       "                                ids_one_hops_dict_en  subj_rank    rel_rank  \\\n",
       "0  {'Q8070': 'P487, P948, P3221, P950, P486, P703...      Q8070   has cause   \n",
       "1  {'Q2222': 'P50, P747, P110, P950, P409, P136, ...      Q2222      author   \n",
       "2  {'Q83186': 'P2348, P50, P7439, P747, P8419, P8...     Q83186      author   \n",
       "3  {'Q218': 'P38, P902, P487, P948, P463, P8309, ...       Q218     capital   \n",
       "4  {'Q5928': 'P11194, P463, P8041, P2722, P22, P4...      Q5928  instrument   \n",
       "\n",
       "  rel_rank_id                                           ans_rank  \\\n",
       "0        P828  http://www.wikidata.org/entity/Q7944, http://w...   \n",
       "1         P50             http://www.wikidata.org/entity/Q102513   \n",
       "2         P50                http://www.wikidata.org/entity/Q692   \n",
       "3         P36              http://www.wikidata.org/entity/Q19660   \n",
       "4       P1303  http://www.wikidata.org/entity/Q6607, http://w...   \n",
       "\n",
       "                                      ans_rank_clean  \\\n",
       "0  Q7944, Q60186, Q167903, Q2580904, Q5975740, Q7...   \n",
       "1                                            Q102513   \n",
       "2                                               Q692   \n",
       "3                                             Q19660   \n",
       "4                 Q6607, Q483994, Q626035, Q17172850   \n",
       "\n",
       "                                    pred_obj_maxpred  \\\n",
       "0  http://www.wikidata.org/entity/Q7944, http://w...   \n",
       "1             http://www.wikidata.org/entity/Q102513   \n",
       "2                http://www.wikidata.org/entity/Q692   \n",
       "3              http://www.wikidata.org/entity/Q19660   \n",
       "4  http://www.wikidata.org/entity/Q6607, http://w...   \n",
       "\n",
       "                                      ans_class_rank  \\\n",
       "0  Q7944, Q60186, Q167903, Q2580904, Q5975740, Q7...   \n",
       "1                                            Q102513   \n",
       "2                                               Q692   \n",
       "3                                             Q19660   \n",
       "4                 Q6607, Q483994, Q626035, Q17172850   \n",
       "\n",
       "                                pred_obj_maxpred_lbl  \n",
       "0  Q7944, Q60186, Q167903, Q2580904, Q5975740, Q7...  \n",
       "1                                            Q102513  \n",
       "2                                               Q692  \n",
       "3                                             Q19660  \n",
       "4                 Q6607, Q483994, Q626035, Q17172850  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0284c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rubq['pred_obj_maxpred'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6c0669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [49:37<00:00,  2.51s/it] \n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(range(len(rubq))):\n",
    "    if pd.isna(rubq.loc[k, 'pred_obj_maxpred']):\n",
    "        try:\n",
    "            cur_subjects = rubq.loc[k, 'bela_base_ents'].split(', ')\n",
    "            for w in range(len(cur_subjects)):\n",
    "                time.sleep(1)\n",
    "                cur_subj = rubq.loc[k, 'bela_base_ents'].split(', ')[w]\n",
    "                cur_rel = rubq.loc[k, 'max_pred_id'].split(', ')[0]\n",
    "                obj_pred = run_query_object(cur_subj, cur_rel)\n",
    "                if len(obj_pred) > 0:\n",
    "                    rubq.loc[k, 'pred_obj_maxpred'] = obj_pred\n",
    "                    break\n",
    "        except:\n",
    "            time.sleep(1)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84571020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1186/1186 [00:00<00:00, 13465.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for j in tqdm(range(len(rubq))):\n",
    "    if pd.notna(rubq.loc[j, 'pred_obj_maxpred']):\n",
    "        cands = rubq.loc[j, 'pred_obj_maxpred'].split(', ')\n",
    "        elems = []\n",
    "        for k in range(len(cands)):\n",
    "            if 'entity/' in cands[k]:\n",
    "                elems.append(cands[k].split('entity/')[1])\n",
    "            else:\n",
    "                elems.append(cands[k])\n",
    "        rubq.loc[j, 'pred_obj_maxpred_lbl'] = ', '.join(elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e3807145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4536256323777403\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(rubq)):\n",
    "    ans = rubq.loc[i, 'ans_rank_clean']\n",
    "    if ans == rubq.loc[i, 'answers']:\n",
    "        count += 1\n",
    "print(count/len(rubq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4a825134",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubq.to_csv('rubq_paper_res_sel_rank.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
